---
article: true
author: Neonscape
date: 2024-12-14
image: /assets/imgs/202412/202412_5.png
cover: /assets/imgs/202412/202412_6.png
category:
  - notes
tag:
  - machine learning
  - review
---

# 机器学习 复习

## 一 绪论

### 1.1 NFL（没有免费的午餐）定理

对于某一个学习算法$\mathcal{L_a}$，将$\mathcal{L_a}$对于问题$f$在训练集以外样本上的误差对于所有$f$求和，得到的结果与$\mathcal{L_a}$无关。

在**不关注要解决的问题**的前提下，**没有哪一种算法**比其他算法更好。

## 二 模型评估与选择

### 2.1 相关概念

- 经验误差
  - 在训练集上产生的误差
  - 太低会产生 **欠拟合**（特征学习不完全），太高会产生 **过拟合**（学习到不存在的特征）
- 测试误差
  - 在测试集上产生的误差
- 泛化误差
  - 在训练集以外的所有（将要接受的）样本上的误差
  - 应当被最小化

### 2.2 评估方法

对模型进行评估需要用于评估的 **测试集**。

选择测试集的常用方法：

- 留出法
  - 将原始数据集划分为两个互斥的子集
  - 多次随机划分，取平均作为最终评估结果。
  - **优点**
    - 简单
  - **缺点**
    - 可能因为划分方法不同导致结果差异较大
    - 数据集较小时，训练集数据可能不足。
- 交叉验证法
  - 将原始数据集划分为`k`个相等大小的折`(fold)`.
  - 将以下过程进行`k`次：
    - 第`i`次选择除了第`i`折以外的所有折作为训练集，第`i`折作为测试集。
  - 将`k`次评估结果的平均作为最终的评估结果。
  - 重复`m`次，取平均作为最终评估结果。
  - **优点**
    - 减少了随机性对于评估的影响（相对于留出法）。
    - 能够更充分利用数据（适用于数据集较小的情况）。
  - **缺点**
    - 计算开销较大。
    - 不适用于不平衡数据集。（折和折之间的样本类别比例可能不同）
- 自助法
  - 从原始数据集中 **有放回的** 抽取`n`个样本，作为训练集。
  - 未被抽到的样本作为测试集。
  - 重复`m`次，取平均作为最终评估结果。
  - 测试集中，**大约`1/3`（`1 / e`）的样本未在训练集中出现过**。
  - 适用于**集成学习**。
  - **优点**
    - 适用于数据集较小的情况。
    - 减少了随机性的影响。
  - **缺点**
    - 计算开销较大。
    - 生成的数据集中可能包含重复样本，导致过拟合。

### 2.3 性能度量

- 回归问题
  - 平均绝对误差（MAE）
  - 均方误差（MSE）
  - 均方根误差（RMSE）
  - R2
- 分类问题
  - 错误率（Error Rate）
    - 被错分的样本占样本总数的比例
  - 准确率（Accuracy）
    - 所有样本被正确分类的比例
    - `(TP + TN) / (N)`
  - 精确率（Precision）/ 查准率
    - 在被分类为正面的样本中，真正为正面样本的比例
    - `TP / (TP + FP)`
  - 召回率（Recall） / 真正例率（TPR） / 查全率
    - 被正确分类的**正面样本**占**全部正面样本**的比例
    - `TP / TP + FN`
  - 假正例率（FPR）
    - 被错误分类为正面的**负面样本**占**全部负面样本**的比例
    - `FP / FP + TN`
  - P-R曲线
    - 以召回率（查全率）为横轴，精确率（查准率）为纵轴，将每个样本作为正例进行预测，绘制出的曲线。
    - 在PR图中，某个分类器的曲线在另一个分类器之上，意味着该分类的表现优于另一个分类器。
    - 平衡点：PR曲线上查准率和查全率相等时的点。
      - 当P-R曲线存在交点时，平衡点也能够用来衡量分类器的表现。
  - F1
    - `F1 = 2 * (P * R) / (P + R)`; 其中P, R分别为精确率、召回率。
  - ROC
    - 以 **假正例率(FP)** 作为横轴， **真正例率(TP)** 作为纵轴，将每个样本作为正例进行预测，绘制出的曲线。
    - 如果某个学习器的ROC曲线覆盖了另一个学习器，则该学习器的表现优于另一个学习器。
  - AUC
    - ROC曲线下的面积
    - 当两条ROC曲线存在交点时，可用来衡量两个学习器的相对表现。

:::info 宏 / 微查全（准）率

- 微查全率 / 微查准率： 在 某一次训练 / 测试中所得到的查全率 / 查准率
- 微F1： 从微查全率 / 微查准率所计算得出的F1指标
- 宏查全率 / 宏查准率： 所有测试的微查全率 / 微查准率的平均
- 宏F1： 从宏查全率 / 宏查准率所计算出的F1指标

:::

:::info 代价曲线

代价曲线是不同类型的错误拥有不相等的代价时使用的度量手段。

代价曲线是以正例概率代价(实际代价 / 最大代价)为横轴，归一化代价(代价的期望 / 最大代价的期望)为纵轴的曲线。

代价曲线的绘制方法：

> 对于ROC曲线上的每一个点，在代价曲线上绘制一条`(0, FPR) -> (1, FNR)`的线段。
>
> 取所有线段的下界即为代价曲线。

:::

### 2.4 比较检验

我们在测试集上取得测试结果后，并不能直接将测试结果作为比较学习器的依据:

- 测试集的性能不等于泛化性能。
- 很多机器学习算法具有随机性。
- 测试性能随着测试集的变化而变化。

因此，我们需要 **假设检验**。

#### 交叉验证t检验

交叉验证t检验用于对比 **两个** 学习器的性能。

过程：

- 对两个学习器进行k折交叉验证。
- 计算两个模型的结果差异。
- 对结果差异进行t检验，计算结果是否显著。

问题：由于采用了交叉验证，因此测试的错误率并不独立；通常采用 **5×2交叉验证** 以解决这个问题。

#### 5×2交叉验证

*TODO

#### McNemar检验

McNemar检验用于判断两个分类器在同一数据集上的分类一致性。

#### Friedman检验

Friedman检验用于比较多个学习器的性能。

#### Nemenyi后续检验

当“所有算法的性能相同”假设被拒绝，则可以采用Nemenyi后续检验来进一步比较不同算法的表现差异。

### 2.5 偏差、方差

对于回归任务，我们通常使用偏差-方差分解来衡量 **泛化误差**。

$$
\begin{aligned}
  E(f; D) = bias^2(x) + var(x) + \epsilon^2(x)
\end{aligned}
$$

- 偏差（bias）
  - 模型对于数据的拟合程度
  - 偏差越大，模型越不拟合数据
  - 较大的偏差说明模型可能过于简单
  - 表达了模型本身的学习能力
- 方差（variance）
  - 模型对于不同数据的拟合程度
  - 方差越大，模型越不稳定
  - 表示了数据扰动所造成的影响
- 噪音（$\epsilon$项）
  - 表示在当前问题上，任意算法所能达到的泛化误差的期望下界
  - 表达了学习任务本身的难度

在一般的训练过程中，随着训练的进行，模型的泛化误差逐渐从偏差主导转变为方差主导。

## 三 线性模型

线性模型试图学习一个通过属性的线性组合来描述的函数。

也可以通过引入层级结构 / 将高维数据映射到低维空间来用线性模型学习非线性函数。

### 3.1 线性回归

线性回归试图学习一个线性模型，来更好的模拟实值的输出标记。

> 如何处理离散特征？
>
> - 将有序的特征连续化
> - 将无序的特征转换为`n`维变量

使用 **最小二乘法** 进行误差估计。

$$
\begin{aligned}
  (w*, b*) = \argmin_{(w, b)} \sum_{i=1}^n (y_i - (w \cdot x_i + b))^2
\end{aligned}
$$

::: info 对数几率回归

对数几率回归是一种 **二分类学习算法** 。

它使用Sigmoid函数$\sigma(x)$将线性模型的任意实数值输出映射到一个$[0, 1]$的概率值，从而实现分类。

假设有

$$
\begin{align}
  z &= \bold{\omega}\bold{x} + \bold{b}
\end{align}
$$

在对数几率回归中，我们假设某样本$\bold{x_i}$属于某一类的几率为$\sigma(z_i)$，属于另一类的几率为$1 - \sigma(z_i)$.

这种方法的优点在于：

- 无需假设数据分布
- 可以直接应用现有的数值优化算法取得最优解

:::

:::info 多变量线性回归

假设有$n$个样本，每个样本有$d$个特征。

假设样本矩阵为$(\bold{x_1}; \bold{x_2}; \cdots; \bold{x_n})$，标记向量为$(y_1, y_2, \dots, y_n)$，权重向量$\bold{ \hat{\omega} } = (\omega_1, \omega_2, \dots, \omega_d, b)$.

利用 **最小二乘法** 进行估计。

有矩阵

$$

\bold{X} = 

\begin{bmatrix}
  x_{11} & x_{12} & \cdots & x_{1d}  & 1\\
  x_{21} & x_{22} & \cdots & x_{2d}  & 1\\
  \vdots & \vdots & \ddots & \vdots & \vdots\\
  x_{n1} & x_{n2} & \cdots & x_{nd} & 1
\end{bmatrix}
$$

有

$$
\bold{\hat{\omega}}^* = \argmin_{\hat{\omega}}(\bold{y} - \bold{X}\hat{\omega})^T(\bold{y} - \bold{X}\hat{\omega})
$$

对$\hat{\omega}$求导得，

$$
\begin{aligned}
  \frac{\partial}{\partial \hat{\omega}}(\bold{y} - \bold{X}\hat{\omega})^T(\bold{y} - \bold{X}\hat{\omega}) &= -2\bold{X}^T(\bold{y} - \bold{X}\hat{\omega})\\
\end{aligned}
$$

当$\bold{X}$为满秩时，解得

$$
\begin{aligned}
  \hat{\omega}^* = (\bold{X}^T\bold{X})^{-1}\bold{X}^T\bold{y}
\end{aligned}
$$

当$\bold{X}$不为满秩时，则$\bold{X}^T\bold{X}$不可逆，此时根据归纳偏好选择解 / 引入正则化项。

:::

### 3.2 二分类任务

#### 线性判别分析 (Linear Discriminant Analysis)

线性判别分析主要用于分类和降维任务。

线性判别分析的目标是 **找到一个线性投影，使得不同类别的数据在投影后的空间上尽可能分开，同类别的数据在投影后的空间上尽可能聚集。**

给定数据集$D = \set{(\bold{x_i}, y_i)}^{m}_{i = 1}, y_i \in \set{0, 1}$, 令$X_i, \bold{\mu_i}, \bold{\Sigma_i}$表示第$i \in \set{0, 1}$类的集合、均值向量、协方差矩阵（$n$个随机变量之间两两的协方差形成的矩阵）。

假设我们要将数据投影至直线$\bold{\omega}$上，则两类样本的协方差分别为$\bold{\omega}^T\bold{\Sigma_0}\bold{\omega}$和$\bold{\omega}^T\bold{\Sigma_1}\bold{\omega}$, 两类样本投影后的中心点分别为$\bold{\omega}^T\mu_0$和$\bold{\omega}^T\mu_1$.

要满足线性判分析的要求，则需要让

$$
\begin{aligned}
  \bold{\omega}^T\Sigma_0\bold{\omega} + \bold{\omega}^T\Sigma_1\bold{\omega}
\end{aligned}
$$
最小，让
$$
\begin{aligned}
  ||\bold{\omega}^T\bold{\mu_0} - \bold{\omega}^T\bold{\mu_1}||^2_2
\end{aligned}
$$
最大。

则可得最大化的目标

$$
\begin{aligned}
  \bold{J} &= \frac{{||\bold{\omega}^T\bold{\mu_0} - \bold{\omega}^T\bold{\mu_1}||^2_2}}{\bold{\omega}^T(\Sigma_0 + \Sigma_1)\bold{\omega} + \bold{\omega}^T\Sigma_1\bold{\omega}} \\
  &= \frac{\bold{\omega}^T(\bold{\mu_0 - \bold{\mu_1})(\bold{\mu_0} - \bold{\mu_1})^T\bold{\omega}}}{\bold{\omega}^T(\Sigma_0 + \Sigma_1)\bold{\omega}} \\
\end{aligned}
$$


### 3.3 多分类任务

解决多分类问题常用的方法是

- 将二分类方法推广到多类
- 将问题进行拆分，拆分为多个二分类问题

其中，问题拆分又分为三种策略：

- 一对一（OvO）
- 一对其他（OvR）
- 多对多（MvM）

#### 一对一分类策略

将$N$类的分类任务拆分为$\frac{N(N - 1)}{2}$个二分类任务，共计$\frac{N(N - 1)}{2}$个分类器。

在预测过程中，将新样本提供给所有分类器进行预测并投票；取票数最多的类别作为最终预测结果。

**优点**：训练所需时间较短（每个分类器训练只需要两类的训练数据）

**缺点**：所需存储空间较大；预测时间较长（每个分类器都需要进行预测）

#### 一对其他分类策略

分别将每一类作为正类，其余类作为反类构建$N$个二分类分类器。

在预测过程中，将新样本提供给所有分类器进行预测，取 **置信度** 最高的预测结果作为最终的预测结果。

**优点**：存储空间较小；预测时间较短

**缺点**：训练所需时间较长（每个分类器都需要训练$N$类的训练数据）

#### 多对多分类策略

多对多分类常常将所有样本类做$M$次划分，每次划分将 **一部分类别划为正类， 一部分类别划为反类**，来训练$M$个二分类器。

一种常用的多对多分类策略为 **纠错输出码（ECOC）**。

纠错输出码将原本数据中的每一个类别与一串长为$M$的序列相对应（如类别$C_1$分别在分类器$f_1, f_2, \dots, f_5$中被划分为`1, -1, -1, 1, 1`， 则类别$C_1$在该分类策略下的输出码为 `[1 -1 -1 1 1]`）。

在预测时，将新样本交给$M$个分类器进行预测，得到新样本的输出码并分别和每一类的输出码计算距离；取 **距离最小的** 类别作为最预测输出。

### 3.4 类别不平衡问题

