---
article: true
author: Neonscape
date: 2024-12-14
image: /assets/imgs/202412/202412_5.png
cover: /assets/imgs/202412/202412_6.png
category:
  - notes
tag:
  - machine learning
  - review
---

# 机器学习 复习

## 一 绪论

### 1.1 NFL（没有免费的午餐）定理

对于某一个学习算法$\mathcal{L_a}$，将$\mathcal{L_a}$对于问题$f$在训练集以外样本上的误差对于所有$f$求和，得到的结果与$\mathcal{L_a}$无关。

在**不关注要解决的问题**的前提下，**没有哪一种算法**比其他算法更好。

## 二 模型评估与选择

### 2.1 相关概念

- 经验误差
  - 在训练集上产生的误差
  - 太低会产生 **欠拟合**（特征学习不完全），太高会产生 **过拟合**（学习到不存在的特征）
- 测试误差
  - 在测试集上产生的误差
- 泛化误差
  - 在训练集以外的所有（将要接受的）样本上的误差
  - 应当被最小化

### 2.2 评估方法

对模型进行评估需要用于评估的 **测试集**。

选择测试集的常用方法：

- 留出法
  - 将原始数据集划分为两个互斥的子集
  - 多次随机划分，取平均作为最终评估结果。
  - **优点**
    - 简单
  - **缺点**
    - 可能因为划分方法不同导致结果差异较大
    - 数据集较小时，训练集数据可能不足。
- 交叉验证法
  - 将原始数据集划分为`k`个相等大小的折`(fold)`.
  - 将以下过程进行`k`次：
    - 第`i`次选择除了第`i`折以外的所有折作为训练集，第`i`折作为测试集。
  - 将`k`次评估结果的平均作为最终的评估结果。
  - 重复`m`次，取平均作为最终评估结果。
  - **优点**
    - 减少了随机性对于评估的影响（相对于留出法）。
    - 能够更充分利用数据（适用于数据集较小的情况）。
  - **缺点**
    - 计算开销较大。
    - 不适用于不平衡数据集。（折和折之间的样本类别比例可能不同）
- 自助法
  - 从原始数据集中 **有放回的** 抽取`n`个样本，作为训练集。
  - 未被抽到的样本作为测试集。
  - 重复`m`次，取平均作为最终评估结果。
  - 测试集中，**大约`1/3`（`1 / e`）的样本未在训练集中出现过**。
  - 适用于**集成学习**。
  - **优点**
    - 适用于数据集较小的情况。
    - 减少了随机性的影响。
  - **缺点**
    - 计算开销较大。
    - 生成的数据集中可能包含重复样本，导致过拟合。

### 2.3 性能度量

- 回归问题
  - 平均绝对误差（MAE）
  - 均方误差（MSE）
  - 均方根误差（RMSE）
  - R2
- 分类问题
  - 错误率（Error Rate）
    - 被错分的样本占样本总数的比例
  - 准确率（Accuracy）
    - 所有样本被正确分类的比例
    - `(TP + TN) / (N)`
  - 精确率（Precision）/ 查准率
    - 在被分类为正面的样本中，真正为正面样本的比例
    - `TP / (TP + FP)`
  - 召回率（Recall） / 真正例率（TPR） / 查全率
    - 被正确分类的**正面样本**占**全部正面样本**的比例
    - `TP / TP + FN`
  - 假正例率（FPR）
    - 被错误分类为正面的**负面样本**占**全部负面样本**的比例
    - `FP / FP + TN`
  - P-R曲线
    - 以召回率（查全率）为横轴，精确率（查准率）为纵轴，将每个样本作为正例进行预测，绘制出的曲线。
    - 在PR图中，某个分类器的曲线在另一个分类器之上，意味着该分类的表现优于另一个分类器。
    - 平衡点：PR曲线上查准率和查全率相等时的点。
  - F1
  - ROC
  - AUC

### 2.4 比较检验
