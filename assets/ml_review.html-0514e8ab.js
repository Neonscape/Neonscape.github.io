import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{o as t,c as e,e as a,a as l,b as s}from"./app-259081b6.js";const n={},r=a('<h1 id="机器学习-复习" tabindex="-1"><a class="header-anchor" href="#机器学习-复习" aria-hidden="true">#</a> 机器学习 复习</h1><h2 id="一-绪论" tabindex="-1"><a class="header-anchor" href="#一-绪论" aria-hidden="true">#</a> 一 绪论</h2><h3 id="_1-1-nfl-没有免费的午餐-定理" tabindex="-1"><a class="header-anchor" href="#_1-1-nfl-没有免费的午餐-定理" aria-hidden="true">#</a> 1.1 NFL（没有免费的午餐）定理</h3>',3),c=l("p",null,[s("对于某一个学习算法"),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("msub",null,[l("mi",{mathvariant:"script"},"L"),l("mi",{mathvariant:"script"},"a")])]),l("annotation",{encoding:"application/x-tex"},"\\mathcal{L_a}")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathcal"},"L"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.1514em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"a")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])])])])]),s("，将"),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("msub",null,[l("mi",{mathvariant:"script"},"L"),l("mi",{mathvariant:"script"},"a")])]),l("annotation",{encoding:"application/x-tex"},"\\mathcal{L_a}")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathcal"},"L"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.1514em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"a")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])])])])]),s("对于问题"),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("mi",null,"f")]),l("annotation",{encoding:"application/x-tex"},"f")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),s("在训练集以外样本上的误差对于所有"),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("mi",null,"f")]),l("annotation",{encoding:"application/x-tex"},"f")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),s("求和，得到的结果与"),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("msub",null,[l("mi",{mathvariant:"script"},"L"),l("mi",{mathvariant:"script"},"a")])]),l("annotation",{encoding:"application/x-tex"},"\\mathcal{L_a}")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathcal"},"L"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.1514em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"a")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])])])])]),s("无关。")],-1),o=a('<p>在<strong>不关注要解决的问题</strong>的前提下，<strong>没有哪一种算法</strong>比其他算法更好。</p><h2 id="二-模型评估与选择" tabindex="-1"><a class="header-anchor" href="#二-模型评估与选择" aria-hidden="true">#</a> 二 模型评估与选择</h2><h3 id="_2-1-相关概念" tabindex="-1"><a class="header-anchor" href="#_2-1-相关概念" aria-hidden="true">#</a> 2.1 相关概念</h3><ul><li>经验误差 <ul><li>在训练集上产生的误差</li><li>太低会产生 <strong>欠拟合</strong>（特征学习不完全），太高会产生 <strong>过拟合</strong>（学习到不存在的特征）</li></ul></li><li>测试误差 <ul><li>在测试集上产生的误差</li></ul></li><li>泛化误差 <ul><li>在训练集以外的所有（将要接受的）样本上的误差</li><li>应当被最小化</li></ul></li></ul><h3 id="_2-2-评估方法" tabindex="-1"><a class="header-anchor" href="#_2-2-评估方法" aria-hidden="true">#</a> 2.2 评估方法</h3><p>对模型进行评估需要用于评估的 <strong>测试集</strong>。</p><p>选择测试集的常用方法：</p><ul><li>留出法 <ul><li>将原始数据集划分为两个互斥的子集</li><li>多次随机划分，取平均作为最终评估结果。</li><li><strong>优点</strong><ul><li>简单</li></ul></li><li><strong>缺点</strong><ul><li>可能因为划分方法不同导致结果差异较大</li><li>数据集较小时，训练集数据可能不足。</li></ul></li></ul></li><li>交叉验证法 <ul><li>将原始数据集划分为<code>k</code>个相等大小的折<code>(fold)</code>.</li><li>将以下过程进行<code>k</code>次： <ul><li>第<code>i</code>次选择除了第<code>i</code>折以外的所有折作为训练集，第<code>i</code>折作为测试集。</li></ul></li><li>将<code>k</code>次评估结果的平均作为最终的评估结果。</li><li>重复<code>m</code>次，取平均作为最终评估结果。</li><li><strong>优点</strong><ul><li>减少了随机性对于评估的影响（相对于留出法）。</li><li>能够更充分利用数据（适用于数据集较小的情况）。</li></ul></li><li><strong>缺点</strong><ul><li>计算开销较大。</li><li>不适用于不平衡数据集。（折和折之间的样本类别比例可能不同）</li></ul></li></ul></li><li>自助法 <ul><li>从原始数据集中 <strong>有放回的</strong> 抽取<code>n</code>个样本，作为训练集。</li><li>未被抽到的样本作为测试集。</li><li>重复<code>m</code>次，取平均作为最终评估结果。</li><li>测试集中，<strong>大约<code>1/3</code>（<code>1 / e</code>）的样本未在训练集中出现过</strong>。</li><li>适用于<strong>集成学习</strong>。</li><li><strong>优点</strong><ul><li>适用于数据集较小的情况。</li><li>减少了随机性的影响。</li></ul></li><li><strong>缺点</strong><ul><li>计算开销较大。</li><li>生成的数据集中可能包含重复样本，导致过拟合。</li></ul></li></ul></li></ul><h3 id="_2-3-性能度量" tabindex="-1"><a class="header-anchor" href="#_2-3-性能度量" aria-hidden="true">#</a> 2.3 性能度量</h3><ul><li>回归问题 <ul><li>平均绝对误差（MAE）</li><li>均方误差（MSE）</li><li>均方根误差（RMSE）</li><li>R2</li></ul></li><li>分类问题 <ul><li>错误率（Error Rate） <ul><li>被错分的样本占样本总数的比例</li></ul></li><li>准确率（Accuracy） <ul><li>所有样本被正确分类的比例</li><li><code>(TP + TN) / (N)</code></li></ul></li><li>精确率（Precision）/ 查准率 <ul><li>在被分类为正面的样本中，真正为正面样本的比例</li><li><code>TP / (TP + FP)</code></li></ul></li><li>召回率（Recall） / 真正例率（TPR） / 查全率 <ul><li>被正确分类的<strong>正面样本</strong>占<strong>全部正面样本</strong>的比例</li><li><code>TP / TP + FN</code></li></ul></li><li>假正例率（FPR） <ul><li>被错误分类为正面的<strong>负面样本</strong>占<strong>全部负面样本</strong>的比例</li><li><code>FP / FP + TN</code></li></ul></li><li>P-R曲线 <ul><li>以召回率（查全率）为横轴，精确率（查准率）为纵轴，将每个样本作为正例进行预测，绘制出的曲线。</li><li>在PR图中，某个分类器的曲线在另一个分类器之上，意味着该分类的表现优于另一个分类器。</li><li>平衡点：PR曲线上查准率和查全率相等时的点。</li></ul></li><li>F1</li><li>ROC</li><li>AUC</li></ul></li></ul><h3 id="_2-4-比较检验" tabindex="-1"><a class="header-anchor" href="#_2-4-比较检验" aria-hidden="true">#</a> 2.4 比较检验</h3>',11),h=[r,c,o];function m(p,d){return t(),e("div",null,h)}const x=i(n,[["render",m],["__file","ml_review.html.vue"]]);export{x as default};
